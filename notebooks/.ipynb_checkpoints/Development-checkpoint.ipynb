{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1e977-f6a7-4058-aad8-67c0d78ea0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b12f52-e2dc-48ce-937c-187de7ee8313",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef442168-fb19-4082-906e-0ced7918e33c",
   "metadata": {},
   "source": [
    "### 1.1 Load Cluster Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f613ba8-cb50-44a8-b796-3a93b9b28b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreId  Department       Date  WeeklySales  IsHoliday\n",
      "0        1           1 2010-05-02     24924.50       True\n",
      "1        1           1 2010-12-02     46039.49       True\n",
      "2        1           1 2010-02-19     41595.55       True\n",
      "3        1           1 2010-02-26     19403.54       True\n",
      "4        1           1 2010-05-03     21827.90       True"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import pandas as pd\n",
    "df = spark.read.format('csv').option('header','true').load(\"/mnt/resource/o9_spark_temp/jhub/5300/martinfabbri_5300/Sales.csv\")\n",
    "sales = df.toPandas()\n",
    "sales['Date'] = pd.to_datetime(sales['Date'])\n",
    "sales['StoreId'] = sales['StoreId'].astype(int)\n",
    "sales['WeeklySales'] = sales['WeeklySales'].astype(float)\n",
    "sales['Department'] = sales['Department'].astype(int)\n",
    "sales['IsHoliday'] = sales['IsHoliday'].astype(bool)\n",
    "\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d106c71-a5c9-498b-8d33-95c6c7b77cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc564e-edc6-4516-8095-24932e0939d4",
   "metadata": {},
   "source": [
    "### 1.2 Load EKG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cda5295-d48d-4683-ac10-ac90807bd26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreId StoreType StoreSize\n",
      "0        1         A    151315\n",
      "1       10         B    126512\n",
      "2       11         A    207499\n",
      "3       12         B    112238\n",
      "4       13         A    219622"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "from o9_ibpl_magics import spark_ibpl\n",
    "\n",
    "df = spark_ibpl('select ([Store].[Store_ID] * [Store].[Type] * [Store].[Size]) on column;',spark)\n",
    "\n",
    "stores_df = df.withColumnRenamed(\"StoreStoreID\",\"StoreId\")\n",
    "stores = stores_df.toPandas()\n",
    "stores['StoreId']  = stores['StoreId'].astype(int)\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4704b1-ce64-4192-85fd-d74ae147b9e8",
   "metadata": {},
   "source": [
    "### 1.3 Load External Dataset - Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8277f656-5493-4a78-9bac-980ac09681ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreId       Date  Temperature  ...         CPI  Unemployment  IsHoliday\n",
      "0        1 2010-05-02        42.31  ...  211.096358         8.106      False\n",
      "1        1 2010-12-02        38.51  ...  211.242170         8.106       True\n",
      "2        1 2010-02-19        39.93  ...  211.289143         8.106      False\n",
      "3        1 2010-02-26        46.63  ...  211.319643         8.106      False\n",
      "4        1 2010-05-03        46.50  ...  211.350143         8.106      False\n",
      "\n",
      "[5 rows x 12 columns]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "csv_path = \"https://o9demostorage.blob.core.windows.net/o9demodata/Features.csv\"\n",
    "features = pd.read_csv(csv_path, encoding='utf8')\n",
    "features['Date'] = pd.to_datetime(features['Date'])\n",
    "features['StoreId']  = features['StoreId'].astype(int)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec3be8-f676-47ad-82bf-c8e4b97ff803",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160c38b-73d7-4336-90dd-b3b84a22ad8d",
   "metadata": {},
   "source": [
    "### 2.1 Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb173acc-3fcd-4513-867c-2298c922bb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreId  Department       Date  ...  StoreType  StoreSize  Type\n",
      "0        1           1 2010-05-02  ...          A     151315     0\n",
      "1        1           1 2010-12-02  ...          A     151315     0\n",
      "2        1           1 2010-02-19  ...          A     151315     0\n",
      "3        1           1 2010-02-26  ...          A     151315     0\n",
      "4        1           1 2010-05-03  ...          A     151315     0\n",
      "\n",
      "[5 rows x 17 columns]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "df=pd.merge(sales,features, on=['StoreId','Date', 'IsHoliday'], how='left')\n",
    "df=pd.merge(df,stores, on=['StoreId'], how='left')\n",
    "\n",
    "df=df.fillna(0)\n",
    "df['Temperature'] = (df['Temperature']- 32) * 5./9.\n",
    "\n",
    "types_encoded, types = df['StoreType'].factorize()\n",
    "df['Type'] = types_encoded\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80587d9-76d6-45ec-b7ff-3d692c5ee5f7",
   "metadata": {},
   "source": [
    "### 2.2 Remove Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b981a2-c480-4397-b7c1-f514db4e176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data duplicated:0"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "print('training_data duplicated:{}'.format(df.duplicated().sum()))\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03561c5c-7e41-410d-a5bb-5a11ee5feefc",
   "metadata": {},
   "source": [
    "### 2.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b185c25-aada-44a2-96ec-9aae71d30210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 StoreId Department            Date  ... StoreType StoreSize   Type\n",
      "column Type        int64      int64  datetime64[ns]  ...    object    object  int64\n",
      "null values (nb)       0          0               0  ...         0         0      0\n",
      "null values (%)        0          0               0  ...         0         0      0\n",
      "\n",
      "[3 rows x 17 columns]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "tab_info = pd.DataFrame(df.dtypes).T.rename(index={0:'column Type'}) \n",
    "tab_info = tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
    "tab_info = tab_info.append(pd.DataFrame(df.isnull().sum()/df.shape[0]*100).T.\n",
    "                                       rename(index={0: 'null values (%)'}))\n",
    "tab_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8b0a8c-0a79-4496-8db7-7ce5e99d51a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "df_average_sales_week = df.groupby(by=['Date'], as_index=False)['WeeklySales'].sum()\n",
    "df_average_sales = df_average_sales_week.sort_values('WeeklySales', ascending=False)\n",
    "ts = df_average_sales_week.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76de978-190f-47fa-9655-30c30408088f",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe70e38-b263-48a4-8053-da85b5ac6f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_ar_model(ts, orders):  \n",
    "    X=np.array([ ts.values[(i-orders)].squeeze() if i >= np.max(orders) else np.array(len(orders) * [np.nan]) for i in range(len(ts))])\n",
    "    mask = ~np.isnan(X[:,:1]).squeeze()\n",
    "    Y= ts.values\n",
    "    lin_reg=LinearRegression()\n",
    "    lin_reg.fit(X[mask],Y[mask])\n",
    "    print(lin_reg.coef_, lin_reg.intercept_)\n",
    "    print('Score factor: %.2f' % lin_reg.score(X[mask],Y[mask]))\n",
    "    return lin_reg.coef_, lin_reg.intercept_\n",
    "    \n",
    "def predict_ar_model(ts, orders, coef, intercept):\n",
    "    return np.array([np.sum(np.dot(coef, ts.values[(i-orders)].squeeze())) + intercept  if i >= np.max(orders) else np.nan for i in range(len(ts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1b4321-7708-416a-8d99-92e4544ec094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13488444 -0.06693086  0.53027452]] [19022705.56418591]\n",
      "Score factor: 0.41"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import numpy as np\n",
    "orders = np.array([1,6,52])\n",
    "coef, intercept = fit_ar_model(ts,orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d24188-4e51-463a-b892-ba03ab529128",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2990ed5-4bca-4b1a-9aed-0211ee0e9c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0\n",
      "Date                            \n",
      "2012-10-08   [44987134.91007443]\n",
      "2012-10-19   [47516831.19430323]\n",
      "2012-10-26  [45679766.043321975]\n",
      "2012-11-05  [46493833.400539674]\n",
      "2012-12-10   [46741235.19014284]\n",
      "<string>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "pred = pd.DataFrame(index=ts.index, data=predict_ar_model(ts, orders, coef, intercept))\n",
    "pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a5503-2d35-484b-966d-e47254a2c59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b18a5a-c86a-482a-bdc7-8ab1ac5c381b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[AabhasDemo] Tenant Conda Environment",
   "language": "python",
   "name": "sandbox_aabhasdemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
